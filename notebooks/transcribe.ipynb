{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio \n",
    "Be careful not to load unless it is requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "import os, sys, datetime, re, json, importlib\n",
    "from collections import defaultdict\n",
    "from sys import modules\n",
    "from IPython.display import HTML, Javascript\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "pd.set_option('display.max_rows', 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trasncribe using Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../geoapp/transcribe.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../geoapp/transcribe.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# DO NOT EDIT THIS FILE : Generated from scribe/notebooks/transcribe.ipynb\n",
    "#!pip install git+https://github.com/openai/whisper.git\n",
    "\n",
    "from mangorest import mango\n",
    "from  mangorest.mango import webapi\n",
    "import colabexts.utils as colabexts_utils\n",
    "import io, os, librosa, logging, sys\n",
    "\n",
    "logger = logging.getLogger( \"geoapp\" )\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "fn=\"/Users/snarayan/Desktop/data/audio/test.wav\"\n",
    "# ------------------------------------------------------------------------------\n",
    "whisperModel  = None\n",
    "def getModel():\n",
    "    global whisperModel\n",
    "    if ( whisperModel is None):\n",
    "        import whisper\n",
    "        whisperModel = whisper.load_model(\"base\")\n",
    "        #whisperModel.DecodingOptions(fp16 = True) \n",
    "    return whisperModel\n",
    "\n",
    "@webapi(\"/geoaudio/transcribe/\")\n",
    "def transcribe(request=None, file=\"/tmp/test.wav\", offset=0, duration=None, save=\"\", **kwargs): \n",
    "    if ( request and request.FILES.getlist('file')):\n",
    "        for f in request.FILES.getlist('file'):\n",
    "            file = f.read()\n",
    "            if ( save ):\n",
    "                filename = save or '/tmp/test.wav'\n",
    "                logger.info(f'GOT FILE will save to {filename} and transcribe')\n",
    "                with open (f\"{filename}\", \"wb\") as ff:\n",
    "                    ff.write(file)\n",
    "            break;\n",
    "\n",
    "    if (type(file) == str):\n",
    "        logger.info(f'File ...{file}')\n",
    "        if ( not file or not os.path.exists(file)):\n",
    "            return f\"{file}\"\n",
    "        data, sample_rate = librosa.load(file, offset=offset, duration=duration, mono=True, sr=16000)\n",
    "    else:\n",
    "        content = io.BytesIO(file)\n",
    "        logger.info(f'Bytes ... {content.getbuffer().nbytes}')\n",
    "        data, sample_rate = librosa.load(content,sr=16000, mono=True, offset=offset, duration=duration)\n",
    "    \n",
    "    audio, _ = librosa.effects.trim(data)\n",
    "\n",
    "    out = getModel().transcribe(data)\n",
    "    #print(out)\n",
    "    return out['text']\n",
    "\n",
    "if __name__ == '__main__' and not colabexts_utils.inJupyter():\n",
    "    transcribe(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 06:36:34,439 geoapp INFO: File .../tmp/test.wav\n",
      "dyld[31404]: symbol '_CGLSetCurrentContext' missing from root that overrides /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib. Use of that symbol in /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL is being set to 0xBAD4007.\n",
      "dyld[31404]: symbol '_CGLGetCurrentContext' missing from root that overrides /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib. Use of that symbol in /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL is being set to 0xBAD4007.\n",
      "dyld[31404]: symbol '_gll_noop' missing from root that overrides /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib. Use of that symbol in /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL is being set to 0xBAD4007.\n",
      "dyld[31404]: symbol '_CGLSetCurrentContext' missing from root that overrides /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib. Use of that symbol in /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL is being set to 0xBAD4007.\n",
      "dyld[31404]: symbol '_CGLGetCurrentContext' missing from root that overrides /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib. Use of that symbol in /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL is being set to 0xBAD4007.\n",
      "dyld[31404]: symbol '_gll_noop' missing from root that overrides /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib. Use of that symbol in /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL is being set to 0xBAD4007.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Welcome to this fifth course on deep learning. In this course, you learn about sequence models, one of the most exciting areas in deep learning. Models like recurrent neural networks or RNNs have transformed speech recognition, national language processing, and other areas. And in this course, you learn how to build these models for yourself. Let's start by looking at a few examples of what sequence models can be useful. In speech recognition, you are given an input audio clip, X, and R-stimap it to a text-short strip. Y. Both the input and the output here are sequence data, because X is an audio clip, so that plays out over time. And Y, the output, is a sequence of words. So sequence models, such as recurrent neural networks and other variations, you learn about a little bit, have been very useful for speech recognition. Music generation is another example of a problem with sequence data. In this case, only the output Y is a sequence. The input can be the empty set, or it can be a single integer, maybe referring to the genre of music you want to generate, or maybe the first few notes of the piece of music you want. But here, X can be nothing, or maybe just an integer, and the output Y is a sequence. In sentiment classification, the input X is a sequence. So given the input phrase, like, there's nothing to like in this movie, how many stars do you think this review would be? Sequence models are also very useful for DNA sequence analysis. So your DNA is represented via the four alphabets ACG and T. And so given a DNA sequence, can you label which part of this DNA sequence say corresponds to a protein? In machine translation, you are given an input sentence, the levution of a quaw, and you're asked to output the translation in a different language. In video activity recognition, you might be given a sequence of video frames and asked to recognize the activity. And in named entity recognition, you might be given a sentence and asked to identify the people in that sentence. So all of these problems can be addressed as supervised learning with label data X, comma Y as the training set. But as you can tell from this list of examples, there are a lot of different types of sequence problems. In some, both the input X and the output Y are sequences. And in that case, sometimes X and Y can have different lengths. Or in this example and this example, X and Y have the same length. And in some of these examples, only either X or only the output Y is a sequence. So in this course, you learn about sequence models that are applicable to all of these different settings. So I hope this gives you a sense of the exciting set of problems that sequence models might be that helps you to address. With that, let's go on to the next video, where we start to define the notation we're used to define these sequence problems.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribe_(file=\"/tmp/test.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = open(\"/tmp/test.wav\", \"rb\").read()\n",
    "b=io.BytesIO(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c), b.getbuffer().nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sample_rate = librosa.load(b,sr=16000, mono=True, offset=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)\n",
    "model.transcribe(data)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
